{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\" , activation= 'relu' ))\n",
    "model.add(Dense(8, kernel_initializer=\"uniform\" , activation= 'relu' ))\n",
    "model.add(Dense(8, kernel_initializer=\"uniform\" , activation= 'relu' ))\n",
    "model.add(Dense(1, kernel_initializer=\"uniform\" , activation= \"sigmoid\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.6804 - accuracy: 0.6510\n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6648 - accuracy: 0.6510\n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6594 - accuracy: 0.6510\n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6526 - accuracy: 0.6510\n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6439 - accuracy: 0.6510\n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6321 - accuracy: 0.6523\n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6209 - accuracy: 0.6719\n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6064 - accuracy: 0.6862\n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5998 - accuracy: 0.6732\n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5948 - accuracy: 0.7044\n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5899 - accuracy: 0.6888\n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5909 - accuracy: 0.6966\n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5887 - accuracy: 0.6914\n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5929 - accuracy: 0.7044\n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5851 - accuracy: 0.7044\n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5905 - accuracy: 0.7044\n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5818 - accuracy: 0.7070\n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5743 - accuracy: 0.7096\n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5760 - accuracy: 0.7031\n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5710 - accuracy: 0.7005\n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5767 - accuracy: 0.7070\n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5658 - accuracy: 0.7174\n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5704 - accuracy: 0.7083\n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5671 - accuracy: 0.7253\n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s 214us/step - loss: 0.5692 - accuracy: 0.7083\n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5652 - accuracy: 0.7201\n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5588 - accuracy: 0.7227\n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5569 - accuracy: 0.7253\n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5643 - accuracy: 0.7331\n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5510 - accuracy: 0.7279\n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5552 - accuracy: 0.7188\n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5513 - accuracy: 0.7357\n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5477 - accuracy: 0.7357\n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5449 - accuracy: 0.7279\n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5530 - accuracy: 0.7161\n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5483 - accuracy: 0.7435\n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5490 - accuracy: 0.7344\n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5517 - accuracy: 0.7331\n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5429 - accuracy: 0.7435\n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5470 - accuracy: 0.7253\n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5348 - accuracy: 0.7552\n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5301 - accuracy: 0.7461\n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5405 - accuracy: 0.7344\n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5360 - accuracy: 0.7474\n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5280 - accuracy: 0.7734\n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5273 - accuracy: 0.7565\n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5261 - accuracy: 0.7552\n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5211 - accuracy: 0.7669\n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5266 - accuracy: 0.7487\n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5193 - accuracy: 0.7656\n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5133 - accuracy: 0.7604\n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5083 - accuracy: 0.7669\n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5105 - accuracy: 0.7630\n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5128 - accuracy: 0.7617\n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5161 - accuracy: 0.7526\n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5027 - accuracy: 0.7695\n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4996 - accuracy: 0.7591\n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5082 - accuracy: 0.7565\n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5093 - accuracy: 0.7565\n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5010 - accuracy: 0.7565\n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5020 - accuracy: 0.7591\n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4907 - accuracy: 0.7591\n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4945 - accuracy: 0.7669\n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4926 - accuracy: 0.7643\n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4967 - accuracy: 0.7643\n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4940 - accuracy: 0.7604\n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4875 - accuracy: 0.7734\n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4925 - accuracy: 0.7552\n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4876 - accuracy: 0.7812\n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4802 - accuracy: 0.7747\n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4822 - accuracy: 0.7617\n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4982 - accuracy: 0.7695\n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4868 - accuracy: 0.7630\n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4803 - accuracy: 0.7747\n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4823 - accuracy: 0.7617\n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4743 - accuracy: 0.7604\n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4899 - accuracy: 0.7617\n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4789 - accuracy: 0.7721\n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4781 - accuracy: 0.7656\n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4796 - accuracy: 0.7682\n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4833 - accuracy: 0.7630\n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4803 - accuracy: 0.7721\n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4961 - accuracy: 0.7604\n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4815 - accuracy: 0.7513\n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4879 - accuracy: 0.7565\n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4849 - accuracy: 0.7826\n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.4752 - accuracy: 0.7656\n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4727 - accuracy: 0.7682\n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4691 - accuracy: 0.7812\n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4721 - accuracy: 0.7747\n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.4661 - accuracy: 0.7760\n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4704 - accuracy: 0.7695\n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4754 - accuracy: 0.7682\n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.4770 - accuracy: 0.7643\n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4700 - accuracy: 0.7630\n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4777 - accuracy: 0.7708\n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.4646 - accuracy: 0.7812\n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4718 - accuracy: 0.7682\n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4601 - accuracy: 0.7826\n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4742 - accuracy: 0.7617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af22af5c50>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 61us/step\n",
      "accuracy: 79.17%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 293\n",
      "Trainable params: 293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/100\n",
      "514/514 [==============================] - 0s 304us/step - loss: 0.4778 - accuracy: 0.7802 - val_loss: 0.4380 - val_accuracy: 0.7953\n",
      "Epoch 2/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4844 - accuracy: 0.7471 - val_loss: 0.4380 - val_accuracy: 0.7835\n",
      "Epoch 3/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4825 - accuracy: 0.7665 - val_loss: 0.4303 - val_accuracy: 0.7953\n",
      "Epoch 4/100\n",
      "514/514 [==============================] - 0s 274us/step - loss: 0.4812 - accuracy: 0.7724 - val_loss: 0.4274 - val_accuracy: 0.8031\n",
      "Epoch 5/100\n",
      "514/514 [==============================] - 0s 274us/step - loss: 0.4812 - accuracy: 0.7704 - val_loss: 0.4292 - val_accuracy: 0.7992\n",
      "Epoch 6/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4740 - accuracy: 0.7879 - val_loss: 0.4279 - val_accuracy: 0.7953\n",
      "Epoch 7/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4814 - accuracy: 0.7626 - val_loss: 0.4499 - val_accuracy: 0.7874\n",
      "Epoch 8/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4949 - accuracy: 0.7549 - val_loss: 0.4358 - val_accuracy: 0.7913\n",
      "Epoch 9/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4872 - accuracy: 0.7549 - val_loss: 0.4297 - val_accuracy: 0.7953\n",
      "Epoch 10/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4726 - accuracy: 0.7646 - val_loss: 0.4276 - val_accuracy: 0.7992\n",
      "Epoch 11/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4697 - accuracy: 0.7821 - val_loss: 0.4167 - val_accuracy: 0.7953\n",
      "Epoch 12/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4785 - accuracy: 0.7704 - val_loss: 0.4287 - val_accuracy: 0.7992\n",
      "Epoch 13/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4712 - accuracy: 0.7685 - val_loss: 0.4477 - val_accuracy: 0.7638\n",
      "Epoch 14/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4758 - accuracy: 0.7607 - val_loss: 0.4409 - val_accuracy: 0.8031\n",
      "Epoch 15/100\n",
      "514/514 [==============================] - 0s 304us/step - loss: 0.4729 - accuracy: 0.7665 - val_loss: 0.4393 - val_accuracy: 0.7913\n",
      "Epoch 16/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4324 - val_accuracy: 0.7992\n",
      "Epoch 17/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4652 - accuracy: 0.7879 - val_loss: 0.4391 - val_accuracy: 0.7913\n",
      "Epoch 18/100\n",
      "514/514 [==============================] - 0s 274us/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.4283 - val_accuracy: 0.7835\n",
      "Epoch 19/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4673 - accuracy: 0.7879 - val_loss: 0.4323 - val_accuracy: 0.7874\n",
      "Epoch 20/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4662 - accuracy: 0.7568 - val_loss: 0.4375 - val_accuracy: 0.8071\n",
      "Epoch 21/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4626 - accuracy: 0.7763 - val_loss: 0.4612 - val_accuracy: 0.7874\n",
      "Epoch 22/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4806 - accuracy: 0.7568 - val_loss: 0.4579 - val_accuracy: 0.7913\n",
      "Epoch 23/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4618 - accuracy: 0.7840 - val_loss: 0.4350 - val_accuracy: 0.7992\n",
      "Epoch 24/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.4478 - val_accuracy: 0.7874\n",
      "Epoch 25/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4680 - accuracy: 0.7704 - val_loss: 0.4433 - val_accuracy: 0.7835\n",
      "Epoch 26/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4770 - accuracy: 0.7763 - val_loss: 0.4803 - val_accuracy: 0.7677\n",
      "Epoch 27/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4641 - accuracy: 0.7802 - val_loss: 0.4352 - val_accuracy: 0.7992\n",
      "Epoch 28/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4623 - accuracy: 0.7840 - val_loss: 0.4531 - val_accuracy: 0.7913\n",
      "Epoch 29/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4576 - accuracy: 0.7899 - val_loss: 0.4619 - val_accuracy: 0.7913\n",
      "Epoch 30/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4577 - accuracy: 0.7724 - val_loss: 0.4516 - val_accuracy: 0.7913\n",
      "Epoch 31/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4713 - accuracy: 0.7685 - val_loss: 0.4317 - val_accuracy: 0.7913\n",
      "Epoch 32/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4614 - accuracy: 0.7782 - val_loss: 0.4454 - val_accuracy: 0.7874\n",
      "Epoch 33/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4624 - accuracy: 0.7685 - val_loss: 0.4439 - val_accuracy: 0.7913\n",
      "Epoch 34/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4602 - accuracy: 0.7782 - val_loss: 0.4443 - val_accuracy: 0.7992\n",
      "Epoch 35/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4727 - accuracy: 0.7821 - val_loss: 0.4700 - val_accuracy: 0.7795\n",
      "Epoch 36/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4649 - accuracy: 0.7763 - val_loss: 0.4519 - val_accuracy: 0.7756\n",
      "Epoch 37/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4566 - accuracy: 0.7821 - val_loss: 0.4425 - val_accuracy: 0.7953\n",
      "Epoch 38/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4617 - accuracy: 0.7782 - val_loss: 0.4489 - val_accuracy: 0.7992\n",
      "Epoch 39/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4554 - accuracy: 0.7879 - val_loss: 0.4283 - val_accuracy: 0.7953\n",
      "Epoch 40/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4636 - accuracy: 0.7763 - val_loss: 0.4372 - val_accuracy: 0.7953\n",
      "Epoch 41/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4527 - accuracy: 0.7743 - val_loss: 0.4448 - val_accuracy: 0.7835\n",
      "Epoch 42/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4620 - accuracy: 0.7938 - val_loss: 0.4473 - val_accuracy: 0.7913\n",
      "Epoch 43/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4566 - accuracy: 0.7879 - val_loss: 0.4370 - val_accuracy: 0.7913\n",
      "Epoch 44/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.4386 - val_accuracy: 0.7953\n",
      "Epoch 45/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4533 - accuracy: 0.7821 - val_loss: 0.4369 - val_accuracy: 0.7992\n",
      "Epoch 46/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4597 - accuracy: 0.7704 - val_loss: 0.4390 - val_accuracy: 0.7874\n",
      "Epoch 47/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4560 - accuracy: 0.7957 - val_loss: 0.4374 - val_accuracy: 0.7953\n",
      "Epoch 48/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4550 - accuracy: 0.7879 - val_loss: 0.4377 - val_accuracy: 0.7913\n",
      "Epoch 49/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4661 - accuracy: 0.7763 - val_loss: 0.4738 - val_accuracy: 0.7756\n",
      "Epoch 50/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4768 - accuracy: 0.7393 - val_loss: 0.4602 - val_accuracy: 0.7756\n",
      "Epoch 51/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4566 - accuracy: 0.7879 - val_loss: 0.4411 - val_accuracy: 0.7992\n",
      "Epoch 52/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.4806 - val_accuracy: 0.7677\n",
      "Epoch 53/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4560 - accuracy: 0.7743 - val_loss: 0.4639 - val_accuracy: 0.7756\n",
      "Epoch 54/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4590 - accuracy: 0.7860 - val_loss: 0.4329 - val_accuracy: 0.7913\n",
      "Epoch 55/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4566 - accuracy: 0.7763 - val_loss: 0.4537 - val_accuracy: 0.7953\n",
      "Epoch 56/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4500 - accuracy: 0.7879 - val_loss: 0.4538 - val_accuracy: 0.7874\n",
      "Epoch 57/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4614 - accuracy: 0.7821 - val_loss: 0.4522 - val_accuracy: 0.7913\n",
      "Epoch 58/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4529 - accuracy: 0.7840 - val_loss: 0.4377 - val_accuracy: 0.7992\n",
      "Epoch 59/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4541 - accuracy: 0.7821 - val_loss: 0.4430 - val_accuracy: 0.7913\n",
      "Epoch 60/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4563 - accuracy: 0.7743 - val_loss: 0.4385 - val_accuracy: 0.7953\n",
      "Epoch 61/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4572 - accuracy: 0.7860 - val_loss: 0.4382 - val_accuracy: 0.8031\n",
      "Epoch 62/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4533 - accuracy: 0.7821 - val_loss: 0.4812 - val_accuracy: 0.7953\n",
      "Epoch 63/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4583 - accuracy: 0.7763 - val_loss: 0.4481 - val_accuracy: 0.7953\n",
      "Epoch 64/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4768 - accuracy: 0.7588 - val_loss: 0.4491 - val_accuracy: 0.7874\n",
      "Epoch 65/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4545 - accuracy: 0.7821 - val_loss: 0.4389 - val_accuracy: 0.8110\n",
      "Epoch 66/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4689 - accuracy: 0.7782 - val_loss: 0.4596 - val_accuracy: 0.7992\n",
      "Epoch 67/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4510 - accuracy: 0.7802 - val_loss: 0.4587 - val_accuracy: 0.7717\n",
      "Epoch 68/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4499 - accuracy: 0.7821 - val_loss: 0.4387 - val_accuracy: 0.7992\n",
      "Epoch 69/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4452 - accuracy: 0.7860 - val_loss: 0.4318 - val_accuracy: 0.7874\n",
      "Epoch 70/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4524 - accuracy: 0.7879 - val_loss: 0.4404 - val_accuracy: 0.7953\n",
      "Epoch 71/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4446 - accuracy: 0.7957 - val_loss: 0.4447 - val_accuracy: 0.7835\n",
      "Epoch 72/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4440 - accuracy: 0.7957 - val_loss: 0.5012 - val_accuracy: 0.7717\n",
      "Epoch 73/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4956 - accuracy: 0.7471 - val_loss: 0.4463 - val_accuracy: 0.7835\n",
      "Epoch 74/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4662 - accuracy: 0.7626 - val_loss: 0.4473 - val_accuracy: 0.7953\n",
      "Epoch 75/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4597 - accuracy: 0.7840 - val_loss: 0.4365 - val_accuracy: 0.7913\n",
      "Epoch 76/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4487 - accuracy: 0.7782 - val_loss: 0.4440 - val_accuracy: 0.7874\n",
      "Epoch 77/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4451 - accuracy: 0.7860 - val_loss: 0.4592 - val_accuracy: 0.7953\n",
      "Epoch 78/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4474 - accuracy: 0.7899 - val_loss: 0.4566 - val_accuracy: 0.7756\n",
      "Epoch 79/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4525 - accuracy: 0.7860 - val_loss: 0.4439 - val_accuracy: 0.7795\n",
      "Epoch 80/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4613 - accuracy: 0.7840 - val_loss: 0.4480 - val_accuracy: 0.7992\n",
      "Epoch 81/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4732 - accuracy: 0.7724 - val_loss: 0.4402 - val_accuracy: 0.7756\n",
      "Epoch 82/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4542 - accuracy: 0.7802 - val_loss: 0.4510 - val_accuracy: 0.7913\n",
      "Epoch 83/100\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.4369 - accuracy: 0.7782 - val_loss: 0.4608 - val_accuracy: 0.7756\n",
      "Epoch 84/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4488 - accuracy: 0.7802 - val_loss: 0.4485 - val_accuracy: 0.7874\n",
      "Epoch 85/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4475 - accuracy: 0.7996 - val_loss: 0.4529 - val_accuracy: 0.7756\n",
      "Epoch 86/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4485 - accuracy: 0.7879 - val_loss: 0.4563 - val_accuracy: 0.7953\n",
      "Epoch 87/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4649 - accuracy: 0.7860 - val_loss: 0.4451 - val_accuracy: 0.7992\n",
      "Epoch 88/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4499 - accuracy: 0.7996 - val_loss: 0.4469 - val_accuracy: 0.7913\n",
      "Epoch 89/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4472 - accuracy: 0.7802 - val_loss: 0.4470 - val_accuracy: 0.7835\n",
      "Epoch 90/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4474 - accuracy: 0.7918 - val_loss: 0.4605 - val_accuracy: 0.7717\n",
      "Epoch 91/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.4407 - val_accuracy: 0.7992\n",
      "Epoch 92/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4732 - accuracy: 0.7704 - val_loss: 0.4837 - val_accuracy: 0.7756\n",
      "Epoch 93/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4480 - accuracy: 0.7918 - val_loss: 0.4592 - val_accuracy: 0.7992\n",
      "Epoch 94/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4519 - val_accuracy: 0.7717\n",
      "Epoch 95/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4428 - accuracy: 0.7879 - val_loss: 0.4482 - val_accuracy: 0.7835\n",
      "Epoch 96/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4472 - accuracy: 0.7918 - val_loss: 0.4578 - val_accuracy: 0.7953\n",
      "Epoch 97/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4490 - accuracy: 0.7957 - val_loss: 0.4506 - val_accuracy: 0.7953\n",
      "Epoch 98/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4434 - accuracy: 0.7918 - val_loss: 0.4383 - val_accuracy: 0.7835\n",
      "Epoch 99/100\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.4400 - accuracy: 0.7996 - val_loss: 0.4433 - val_accuracy: 0.7717\n",
      "Epoch 100/100\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.4492 - val_accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af2140c400>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y,validation_split=0.33,epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 231 samples\n",
      "Epoch 1/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4297 - accuracy: 0.8026 - val_loss: 0.4823 - val_accuracy: 0.7532\n",
      "Epoch 2/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4249 - accuracy: 0.8026 - val_loss: 0.4772 - val_accuracy: 0.7619\n",
      "Epoch 3/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4307 - accuracy: 0.7989 - val_loss: 0.4743 - val_accuracy: 0.7489\n",
      "Epoch 4/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4179 - accuracy: 0.8101 - val_loss: 0.4902 - val_accuracy: 0.7662\n",
      "Epoch 5/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4184 - accuracy: 0.8101 - val_loss: 0.4822 - val_accuracy: 0.7489\n",
      "Epoch 6/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4311 - accuracy: 0.8007 - val_loss: 0.4907 - val_accuracy: 0.7446\n",
      "Epoch 7/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4304 - accuracy: 0.7914 - val_loss: 0.4960 - val_accuracy: 0.7792\n",
      "Epoch 8/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4276 - accuracy: 0.7970 - val_loss: 0.4887 - val_accuracy: 0.7662\n",
      "Epoch 9/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4213 - accuracy: 0.8082 - val_loss: 0.5117 - val_accuracy: 0.7662\n",
      "Epoch 10/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4195 - accuracy: 0.8082 - val_loss: 0.4847 - val_accuracy: 0.7749\n",
      "Epoch 11/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4146 - accuracy: 0.8156 - val_loss: 0.5027 - val_accuracy: 0.7532\n",
      "Epoch 12/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4228 - accuracy: 0.8082 - val_loss: 0.4876 - val_accuracy: 0.7619\n",
      "Epoch 13/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4150 - accuracy: 0.8063 - val_loss: 0.5001 - val_accuracy: 0.7662\n",
      "Epoch 14/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.4065 - accuracy: 0.8156 - val_loss: 0.4974 - val_accuracy: 0.7749\n",
      "Epoch 15/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4101 - accuracy: 0.8082 - val_loss: 0.5071 - val_accuracy: 0.7316\n",
      "Epoch 16/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4316 - accuracy: 0.7952 - val_loss: 0.5193 - val_accuracy: 0.7273\n",
      "Epoch 17/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4177 - accuracy: 0.8175 - val_loss: 0.5175 - val_accuracy: 0.7403\n",
      "Epoch 18/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4083 - accuracy: 0.8156 - val_loss: 0.5125 - val_accuracy: 0.7619\n",
      "Epoch 19/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.4142 - accuracy: 0.8082 - val_loss: 0.5258 - val_accuracy: 0.7706\n",
      "Epoch 20/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4211 - accuracy: 0.8119 - val_loss: 0.5097 - val_accuracy: 0.7619\n",
      "Epoch 21/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4172 - accuracy: 0.8082 - val_loss: 0.5159 - val_accuracy: 0.7403\n",
      "Epoch 22/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4029 - accuracy: 0.8082 - val_loss: 0.5308 - val_accuracy: 0.7359\n",
      "Epoch 23/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.4081 - accuracy: 0.8119 - val_loss: 0.5248 - val_accuracy: 0.7792\n",
      "Epoch 24/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4086 - accuracy: 0.8045 - val_loss: 0.5112 - val_accuracy: 0.7446\n",
      "Epoch 25/150\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.80 - 0s 204us/step - loss: 0.4157 - accuracy: 0.8212 - val_loss: 0.5185 - val_accuracy: 0.7359\n",
      "Epoch 26/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.4164 - accuracy: 0.8119 - val_loss: 0.5135 - val_accuracy: 0.7706\n",
      "Epoch 27/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4136 - accuracy: 0.8082 - val_loss: 0.5369 - val_accuracy: 0.7446\n",
      "Epoch 28/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4028 - accuracy: 0.8063 - val_loss: 0.5576 - val_accuracy: 0.7229\n",
      "Epoch 29/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.4099 - accuracy: 0.8156 - val_loss: 0.5129 - val_accuracy: 0.7749\n",
      "Epoch 30/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4030 - accuracy: 0.8231 - val_loss: 0.5217 - val_accuracy: 0.7619\n",
      "Epoch 31/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4072 - accuracy: 0.8101 - val_loss: 0.5266 - val_accuracy: 0.7446\n",
      "Epoch 32/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4003 - accuracy: 0.8231 - val_loss: 0.5649 - val_accuracy: 0.7489\n",
      "Epoch 33/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4276 - accuracy: 0.8063 - val_loss: 0.5277 - val_accuracy: 0.7359\n",
      "Epoch 34/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4081 - accuracy: 0.8119 - val_loss: 0.5552 - val_accuracy: 0.7576\n",
      "Epoch 35/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4129 - accuracy: 0.8082 - val_loss: 0.5300 - val_accuracy: 0.7619\n",
      "Epoch 36/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3979 - accuracy: 0.8305 - val_loss: 0.5445 - val_accuracy: 0.7316\n",
      "Epoch 37/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3964 - accuracy: 0.8101 - val_loss: 0.5322 - val_accuracy: 0.7359\n",
      "Epoch 38/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.4028 - accuracy: 0.8156 - val_loss: 0.5389 - val_accuracy: 0.7662\n",
      "Epoch 39/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.3909 - accuracy: 0.8287 - val_loss: 0.5272 - val_accuracy: 0.7619\n",
      "Epoch 40/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.4003 - accuracy: 0.8212 - val_loss: 0.5343 - val_accuracy: 0.7273\n",
      "Epoch 41/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.3852 - accuracy: 0.8343 - val_loss: 0.5294 - val_accuracy: 0.7792\n",
      "Epoch 42/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.4028 - accuracy: 0.8287 - val_loss: 0.5544 - val_accuracy: 0.7273\n",
      "Epoch 43/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.4114 - accuracy: 0.8101 - val_loss: 0.5723 - val_accuracy: 0.7446\n",
      "Epoch 44/150\n",
      "537/537 [==============================] - 0s 378us/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5335 - val_accuracy: 0.7662\n",
      "Epoch 45/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4003 - accuracy: 0.8156 - val_loss: 0.5296 - val_accuracy: 0.7532\n",
      "Epoch 46/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.4191 - accuracy: 0.8063 - val_loss: 0.5380 - val_accuracy: 0.7359\n",
      "Epoch 47/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.3838 - accuracy: 0.8156 - val_loss: 0.5415 - val_accuracy: 0.7359\n",
      "Epoch 48/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3871 - accuracy: 0.8082 - val_loss: 0.5609 - val_accuracy: 0.7229\n",
      "Epoch 49/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3838 - accuracy: 0.8343 - val_loss: 0.5508 - val_accuracy: 0.7316\n",
      "Epoch 50/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.3977 - accuracy: 0.8138 - val_loss: 0.5322 - val_accuracy: 0.7662\n",
      "Epoch 51/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3917 - accuracy: 0.8231 - val_loss: 0.5613 - val_accuracy: 0.7403\n",
      "Epoch 52/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3958 - accuracy: 0.8175 - val_loss: 0.5377 - val_accuracy: 0.7532\n",
      "Epoch 53/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3885 - accuracy: 0.8305 - val_loss: 0.5568 - val_accuracy: 0.7403\n",
      "Epoch 54/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3875 - accuracy: 0.8250 - val_loss: 0.5381 - val_accuracy: 0.7576\n",
      "Epoch 55/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3949 - accuracy: 0.8268 - val_loss: 0.5651 - val_accuracy: 0.7359\n",
      "Epoch 56/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4057 - accuracy: 0.8045 - val_loss: 0.5884 - val_accuracy: 0.7100\n",
      "Epoch 57/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3916 - accuracy: 0.8268 - val_loss: 0.5359 - val_accuracy: 0.7446\n",
      "Epoch 58/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3789 - accuracy: 0.8380 - val_loss: 0.5350 - val_accuracy: 0.7489\n",
      "Epoch 59/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3950 - accuracy: 0.8082 - val_loss: 0.5457 - val_accuracy: 0.7359\n",
      "Epoch 60/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3691 - accuracy: 0.8380 - val_loss: 0.6254 - val_accuracy: 0.7229\n",
      "Epoch 61/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.4097 - accuracy: 0.8138 - val_loss: 0.5864 - val_accuracy: 0.7316\n",
      "Epoch 62/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3927 - accuracy: 0.8138 - val_loss: 0.5354 - val_accuracy: 0.7619\n",
      "Epoch 63/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3947 - accuracy: 0.8287 - val_loss: 0.5509 - val_accuracy: 0.7359\n",
      "Epoch 64/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3807 - accuracy: 0.8305 - val_loss: 0.5496 - val_accuracy: 0.7489\n",
      "Epoch 65/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3789 - accuracy: 0.8231 - val_loss: 0.5486 - val_accuracy: 0.7359\n",
      "Epoch 66/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3923 - accuracy: 0.8194 - val_loss: 0.5363 - val_accuracy: 0.7576\n",
      "Epoch 67/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.3800 - accuracy: 0.8417 - val_loss: 0.5670 - val_accuracy: 0.7446\n",
      "Epoch 68/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3802 - accuracy: 0.8287 - val_loss: 0.5479 - val_accuracy: 0.7532\n",
      "Epoch 69/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3882 - accuracy: 0.8324 - val_loss: 0.5661 - val_accuracy: 0.7489\n",
      "Epoch 70/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3800 - accuracy: 0.8212 - val_loss: 0.5359 - val_accuracy: 0.7532\n",
      "Epoch 71/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3742 - accuracy: 0.8250 - val_loss: 0.5519 - val_accuracy: 0.7316\n",
      "Epoch 72/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3831 - accuracy: 0.8231 - val_loss: 0.5419 - val_accuracy: 0.7619\n",
      "Epoch 73/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3874 - accuracy: 0.8324 - val_loss: 0.5501 - val_accuracy: 0.7273\n",
      "Epoch 74/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3822 - accuracy: 0.8380 - val_loss: 0.5806 - val_accuracy: 0.7229\n",
      "Epoch 75/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.3752 - accuracy: 0.8343 - val_loss: 0.5625 - val_accuracy: 0.7403\n",
      "Epoch 76/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3839 - accuracy: 0.8324 - val_loss: 0.5670 - val_accuracy: 0.7359\n",
      "Epoch 77/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3842 - accuracy: 0.8343 - val_loss: 0.5652 - val_accuracy: 0.7576\n",
      "Epoch 78/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3825 - accuracy: 0.8250 - val_loss: 0.6153 - val_accuracy: 0.7100\n",
      "Epoch 79/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3973 - accuracy: 0.8119 - val_loss: 0.5911 - val_accuracy: 0.7273\n",
      "Epoch 80/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3795 - accuracy: 0.8250 - val_loss: 0.5672 - val_accuracy: 0.7446\n",
      "Epoch 81/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3688 - accuracy: 0.8380 - val_loss: 0.5424 - val_accuracy: 0.7489\n",
      "Epoch 82/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3731 - accuracy: 0.8250 - val_loss: 0.5668 - val_accuracy: 0.7316\n",
      "Epoch 83/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3748 - accuracy: 0.8212 - val_loss: 0.5609 - val_accuracy: 0.7143\n",
      "Epoch 84/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3812 - accuracy: 0.8417 - val_loss: 0.5680 - val_accuracy: 0.7446\n",
      "Epoch 85/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3815 - accuracy: 0.8305 - val_loss: 0.5681 - val_accuracy: 0.7186\n",
      "Epoch 86/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3838 - accuracy: 0.8194 - val_loss: 0.5754 - val_accuracy: 0.7316\n",
      "Epoch 87/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3750 - accuracy: 0.8324 - val_loss: 0.5625 - val_accuracy: 0.7359\n",
      "Epoch 88/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3982 - accuracy: 0.8194 - val_loss: 0.5884 - val_accuracy: 0.7446\n",
      "Epoch 89/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3818 - accuracy: 0.8268 - val_loss: 0.5530 - val_accuracy: 0.7619\n",
      "Epoch 90/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3861 - accuracy: 0.8212 - val_loss: 0.5669 - val_accuracy: 0.7489\n",
      "Epoch 91/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3866 - accuracy: 0.8305 - val_loss: 0.6120 - val_accuracy: 0.7359\n",
      "Epoch 92/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3793 - accuracy: 0.8268 - val_loss: 0.5720 - val_accuracy: 0.7532\n",
      "Epoch 93/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3939 - accuracy: 0.8119 - val_loss: 0.5743 - val_accuracy: 0.7403\n",
      "Epoch 94/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3706 - accuracy: 0.8324 - val_loss: 0.5621 - val_accuracy: 0.7403\n",
      "Epoch 95/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3727 - accuracy: 0.8287 - val_loss: 0.5911 - val_accuracy: 0.7316\n",
      "Epoch 96/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3723 - accuracy: 0.8287 - val_loss: 0.5639 - val_accuracy: 0.7706\n",
      "Epoch 97/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3869 - accuracy: 0.8324 - val_loss: 0.5567 - val_accuracy: 0.7446\n",
      "Epoch 98/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3868 - accuracy: 0.8361 - val_loss: 0.5781 - val_accuracy: 0.7273\n",
      "Epoch 99/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.3753 - accuracy: 0.8268 - val_loss: 0.5894 - val_accuracy: 0.7403\n",
      "Epoch 100/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.3809 - accuracy: 0.8250 - val_loss: 0.5506 - val_accuracy: 0.7316\n",
      "Epoch 101/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3815 - accuracy: 0.8361 - val_loss: 0.5740 - val_accuracy: 0.7316\n",
      "Epoch 102/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3732 - accuracy: 0.8436 - val_loss: 0.5701 - val_accuracy: 0.7749\n",
      "Epoch 103/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3681 - accuracy: 0.8305 - val_loss: 0.5649 - val_accuracy: 0.7532\n",
      "Epoch 104/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3612 - accuracy: 0.8380 - val_loss: 0.6063 - val_accuracy: 0.7316\n",
      "Epoch 105/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3722 - accuracy: 0.8268 - val_loss: 0.5603 - val_accuracy: 0.7446\n",
      "Epoch 106/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3672 - accuracy: 0.8287 - val_loss: 0.5657 - val_accuracy: 0.7576\n",
      "Epoch 107/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3734 - accuracy: 0.8324 - val_loss: 0.5748 - val_accuracy: 0.7273\n",
      "Epoch 108/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.3600 - accuracy: 0.8454 - val_loss: 0.5872 - val_accuracy: 0.7446\n",
      "Epoch 109/150\n",
      "537/537 [==============================] - 0s 291us/step - loss: 0.3690 - accuracy: 0.8380 - val_loss: 0.6100 - val_accuracy: 0.7316\n",
      "Epoch 110/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3776 - accuracy: 0.8212 - val_loss: 0.5583 - val_accuracy: 0.7273\n",
      "Epoch 111/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3642 - accuracy: 0.8454 - val_loss: 0.5965 - val_accuracy: 0.7359\n",
      "Epoch 112/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3787 - accuracy: 0.8343 - val_loss: 0.5733 - val_accuracy: 0.7359\n",
      "Epoch 113/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3696 - accuracy: 0.8231 - val_loss: 0.5769 - val_accuracy: 0.7403\n",
      "Epoch 114/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3670 - accuracy: 0.8305 - val_loss: 0.5865 - val_accuracy: 0.7532\n",
      "Epoch 115/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3864 - accuracy: 0.8212 - val_loss: 0.5803 - val_accuracy: 0.7403\n",
      "Epoch 116/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3674 - accuracy: 0.8231 - val_loss: 0.5909 - val_accuracy: 0.7403\n",
      "Epoch 117/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3654 - accuracy: 0.8324 - val_loss: 0.5725 - val_accuracy: 0.7489\n",
      "Epoch 118/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3646 - accuracy: 0.8417 - val_loss: 0.5834 - val_accuracy: 0.7359\n",
      "Epoch 119/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3763 - accuracy: 0.8287 - val_loss: 0.5761 - val_accuracy: 0.7576\n",
      "Epoch 120/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3589 - accuracy: 0.8287 - val_loss: 0.5720 - val_accuracy: 0.7489\n",
      "Epoch 121/150\n",
      "537/537 [==============================] - 0s 320us/step - loss: 0.3599 - accuracy: 0.8436 - val_loss: 0.5631 - val_accuracy: 0.7532\n",
      "Epoch 122/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3593 - accuracy: 0.8454 - val_loss: 0.5763 - val_accuracy: 0.7446\n",
      "Epoch 123/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3546 - accuracy: 0.8305 - val_loss: 0.5804 - val_accuracy: 0.7446\n",
      "Epoch 124/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3749 - accuracy: 0.8343 - val_loss: 0.5801 - val_accuracy: 0.7532\n",
      "Epoch 125/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3703 - accuracy: 0.8305 - val_loss: 0.5767 - val_accuracy: 0.7403\n",
      "Epoch 126/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3623 - accuracy: 0.8436 - val_loss: 0.5748 - val_accuracy: 0.7619\n",
      "Epoch 127/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3625 - accuracy: 0.8343 - val_loss: 0.6102 - val_accuracy: 0.7186\n",
      "Epoch 128/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3760 - accuracy: 0.8305 - val_loss: 0.6000 - val_accuracy: 0.7359\n",
      "Epoch 129/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3734 - accuracy: 0.8343 - val_loss: 0.5711 - val_accuracy: 0.7489\n",
      "Epoch 130/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3602 - accuracy: 0.8380 - val_loss: 0.6025 - val_accuracy: 0.7359\n",
      "Epoch 131/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3638 - accuracy: 0.8231 - val_loss: 0.5795 - val_accuracy: 0.7273\n",
      "Epoch 132/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3656 - accuracy: 0.8305 - val_loss: 0.6210 - val_accuracy: 0.7273\n",
      "Epoch 133/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3667 - accuracy: 0.8250 - val_loss: 0.5710 - val_accuracy: 0.7316\n",
      "Epoch 134/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3640 - accuracy: 0.8361 - val_loss: 0.6086 - val_accuracy: 0.7359\n",
      "Epoch 135/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3837 - accuracy: 0.8324 - val_loss: 0.5874 - val_accuracy: 0.7359\n",
      "Epoch 136/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3636 - accuracy: 0.8380 - val_loss: 0.5773 - val_accuracy: 0.7446\n",
      "Epoch 137/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3573 - accuracy: 0.8287 - val_loss: 0.6209 - val_accuracy: 0.7359\n",
      "Epoch 138/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3602 - accuracy: 0.8343 - val_loss: 0.6145 - val_accuracy: 0.7359\n",
      "Epoch 139/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3612 - accuracy: 0.8361 - val_loss: 0.5959 - val_accuracy: 0.7576\n",
      "Epoch 140/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3519 - accuracy: 0.8399 - val_loss: 0.6025 - val_accuracy: 0.7273\n",
      "Epoch 141/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3532 - accuracy: 0.8361 - val_loss: 0.5894 - val_accuracy: 0.7446\n",
      "Epoch 142/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3470 - accuracy: 0.8380 - val_loss: 0.5897 - val_accuracy: 0.7403\n",
      "Epoch 143/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3542 - accuracy: 0.8417 - val_loss: 0.6045 - val_accuracy: 0.7229\n",
      "Epoch 144/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3620 - accuracy: 0.8417 - val_loss: 0.5899 - val_accuracy: 0.7273\n",
      "Epoch 145/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3467 - accuracy: 0.8510 - val_loss: 0.6007 - val_accuracy: 0.7359\n",
      "Epoch 146/150\n",
      "537/537 [==============================] - 0s 204us/step - loss: 0.3704 - accuracy: 0.8250 - val_loss: 0.6099 - val_accuracy: 0.7403\n",
      "Epoch 147/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3540 - accuracy: 0.8417 - val_loss: 0.6113 - val_accuracy: 0.7186\n",
      "Epoch 148/150\n",
      "537/537 [==============================] - 0s 233us/step - loss: 0.3560 - accuracy: 0.8343 - val_loss: 0.5953 - val_accuracy: 0.7403\n",
      "Epoch 149/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3512 - accuracy: 0.8473 - val_loss: 0.6554 - val_accuracy: 0.7403\n",
      "Epoch 150/150\n",
      "537/537 [==============================] - 0s 262us/step - loss: 0.3492 - accuracy: 0.8454 - val_loss: 0.6025 - val_accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af214002e8>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 68us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6025368984127457, 0.7142857313156128]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StratifiedKFold in module sklearn.model_selection._split:\n",
      "\n",
      "class StratifiedKFold(_BaseKFold)\n",
      " |  Stratified K-Folds cross-validator\n",
      " |  \n",
      " |  Provides train/test indices to split data in train/test sets.\n",
      " |  \n",
      " |  This cross-validation object is a variation of KFold that returns\n",
      " |  stratified folds. The folds are made by preserving the percentage of\n",
      " |  samples for each class.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=5\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``n_splits`` default value changed from 3 to 5.\n",
      " |  \n",
      " |  shuffle : boolean, optional\n",
      " |      Whether to shuffle each class's samples before splitting into batches.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default=None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`. Only used when ``shuffle`` is True. This should be left\n",
      " |      to None if ``shuffle`` is False.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import StratifiedKFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([0, 0, 1, 1])\n",
      " |  >>> skf = StratifiedKFold(n_splits=2)\n",
      " |  >>> skf.get_n_splits(X, y)\n",
      " |  2\n",
      " |  >>> print(skf)\n",
      " |  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for train_index, test_index in skf.split(X, y):\n",
      " |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      " |  TRAIN: [1 3] TEST: [0 2]\n",
      " |  TRAIN: [0 2] TEST: [1 3]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The implementation is designed to:\n",
      " |  \n",
      " |  * Generate test sets such that all contain the same distribution of\n",
      " |    classes, or as close as possible.\n",
      " |  * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n",
      " |    ``y = [1, 0]`` should not change the indices generated.\n",
      " |  * Preserve order dependencies in the dataset ordering, when\n",
      " |    ``shuffle=False``: all samples from class k in some test set were\n",
      " |    contiguous in y, or separated in y by samples from classes other than k.\n",
      " |  * Generate test sets where the smallest and largest differ by at most one\n",
      " |    sample.\n",
      " |  \n",
      " |  .. versionchanged:: 0.22\n",
      " |      The previous implementation did not follow the last constraint.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StratifiedKFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits=5, shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  split(self, X, y, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |          Note that providing ``y`` is sufficient to generate the splits and\n",
      " |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      " |          ``X`` instead of actual training data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |          Stratification is done based on the y labels.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Randomized CV splitters may return different results for each call of\n",
      " |      split. You can make the results identical by setting ``random_state``\n",
      " |      to an integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
